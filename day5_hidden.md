# 신경망의 완성:히든레이어
>강의 링크: https://opentutorials.org/course/4570/28988

퍼셉트론 하나로 구성된 모델이 아닌 깊게 연결된 진짜 신경망 딥러닝 모델을 만들어 봅시다.  

우리는 이미 방법을 모두 배웠습니다. 딥러닝은 기존 배웠던 퍼센트론을 여러개 사용하여 연결하면 되는 것입니다.

![image](https://user-images.githubusercontent.com/55734436/103978443-d0951780-51be-11eb-90d3-95b620411578.png)

그림과 같이 입력층을 **Input Layer** 출력층을 **Output Layer**라고 합니다. 이 입력과 결과 사이에 퍼셉트론을 추가하고 그  부분을 **Hidden Layer**라고 합니다.  

그림에서 Hidden Layer는 5개의 노드를 가지고 있습니다.

![image](https://user-images.githubusercontent.com/55734436/103978450-d3900800-51be-11eb-95a8-d09c04638359.png)

결과를 만들기 위해서는 오른쪽을 보면 히든레이어의 모든 값들을 입력으로 하는 하나의 퍼셉트론이 필요합니다. 그리고 왼쪽을 보면 히든레이어의 첫번째 결과를 만들기 위해서는 하나의 퍼셉트론이 필요하고 노드가 5개이므로 총 5개의 퍼셉트론이 필요하게 됩니다.

![image](https://user-images.githubusercontent.com/55734436/103978454-d559cb80-51be-11eb-8bab-ddc14e21ef67.png)

데이터의 관점에서 생각을 해봅시다. 보스턴 데이터를 떠올려 봅시다. 보스턴 데이터는 (506, 13) 독립변수가 13개의 컬럼으로 입력이 있고 종속변수가 1개의 정답인 컬럼으로 되어 있었습니다.  

13개의 데이터를 입력받아 히든레이어를 통해 5개의 데이터를 출력하고 마지막으로는 1개의 데이터를 출력하게 됩니다.  

이렇게 여러개의 모델을 연속적으로 연결하여 거대한 신경망으로 만드는 것이 바로 **딥러닝 인공신경망**입니다.  

다음으로 히든레이어를 만드는 코드를 살펴보겠습니다.

![image](https://user-images.githubusercontent.com/55734436/103978460-d854bc00-51be-11eb-9b84-061c4177b4ba.png)

다음 코드는 H 변수에 5개의 노드로 구성된 히든레이어를 만들었습니다. 여기서 Y에 들어가는 값은 X가 아닌 H임을 주의해야 합니다.  

코드를 보면 활성화 함수로 **swich**가 있는데 이 함수는 최근 발표된 성능이 좋은 활성화 함수입니다.  

이 히든 레이어는 사용자가 자유롭게 추가할 수 있습니다. 한번 층을 더 쌓도록 해보겠습니다.

![image](https://user-images.githubusercontent.com/55734436/103978466-dab71600-51be-11eb-94c2-af09901032ec.png)

다음과 같이 층을 더 쌓았습니다. 이렇게 하게 되면 성능이 더 좋아지게 됩니다. 하지만 데이터에 따라서 모델이 너무 복잡하면 오히려 더 좋지 않은 결과를 가져올 수 있습니다. 따라서 데이터 특성에 맞게 잘 조절하는 것이 중요합니다.
